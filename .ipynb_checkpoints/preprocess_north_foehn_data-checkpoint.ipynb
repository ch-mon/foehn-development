{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read North Foehn datasets and stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=\"PIO\" # \"PIO\" or \"LUG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1983_2016 = pd.read_csv(f\"data/FoehnData/{location}_1983_2016.txt\", delimiter=\",\", header=0)\n",
    "df_1983_2016[\"Date\"] = pd.to_datetime(df_1983_2016[\"Date\"], format='%Y%m%d%H%M')\n",
    "df_1983_2016.rename(columns= {\"Date\": \"date\", \"Foehn Index\": \"Foehn\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_2019 = pd.read_csv(f\"data/FoehnData/{location}_2017_2019.txt\", delimiter=\";\", skiprows=2, header=0)\n",
    "df_2017_2019[\"time\"] = pd.to_datetime(df_2017_2019[\"time\"], format='%Y%m%d%H%M')\n",
    "df_2017_2019.rename(columns= {\"time\": \"date\", \"wcc006s0\": \"Foehn\"}, inplace=True)\n",
    "df_2017_2019 = df_2017_2019[[\"date\", \"Foehn\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack dataframes.\n",
    "df_1983_2019 = pd.concat([df_1983_2016, df_2017_2019], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure continuoes and consistent values in the \"date\" column\n",
    "df_timeframe = pd.Series(pd.date_range(start = \"1983-01-01 00:00:00\", end=\"2019-12-31 23:50:00\", freq=\"10min\"), name=\"date\")\n",
    "df_1983_2019 = pd.merge(df_timeframe, df_1983_2019, on=\"date\", how=\"left\", validate=\"one_to_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"-\" from Foehn column and transform type to float\n",
    "df_1983_2019[\"Foehn\"] = df_1983_2019[\"Foehn\"].mask(df_1983_2019[\"Foehn\"] ==\"-\", np.NaN)\n",
    "df_1983_2019[\"Foehn\"] = df_1983_2019[\"Foehn\"].astype(float)\n",
    "\n",
    "# Set all Foehn values (Foehn==2) to 1 (i.e. treat Mischluft as normal foehn)\n",
    "df_1983_2019[\"Foehn\"] = df_1983_2019[\"Foehn\"].mask(df_1983_2019[\"Foehn\"] == 2.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rolling window of length 6. If at least 4 dates show Foehn say there is foehn prevalent, otherwise not (refer to Gutermann et. al.(2013))\n",
    "# Allow max 2 missing values (-> min_periods=4). Otherwise set entry to np.NaN\n",
    "foehn_rolling_window=df_1983_2019[\"Foehn\"].rolling(window=6, min_periods=4).sum().shift(-3)\n",
    "foehn_new_representation = (foehn_rolling_window >= 4).astype(int)\n",
    "foehn_new_representation.loc[foehn_rolling_window.isnull()] = np.NaN\n",
    "\n",
    "df_rolling= df_1983_2019.copy()\n",
    "df_rolling[\"Foehn\"]= foehn_new_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only timestamps at full hour and where hour equals 0,6,12 or 18\n",
    "date_mask = (df_rolling[\"date\"].dt.minute==0) & \\\n",
    "            ((df_rolling[\"date\"].dt.hour == 0) | \n",
    "            (df_rolling[\"date\"].dt.hour == 6) |\n",
    "            (df_rolling[\"date\"].dt.hour == 12) |\n",
    "            (df_rolling[\"date\"].dt.hour == 18))\n",
    "df_foehn =df_rolling.loc[date_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.862258\n",
       "1.0    0.137742\n",
       "Name: Foehn, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df_foehn[\"Foehn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foehn.to_csv(f\"data/FoehnData/{location}_foehn.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
