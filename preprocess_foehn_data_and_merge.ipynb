{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read South Foehn datasets and stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1981_1990 = pd.read_csv(\"/net/litho/atmosdyn2/chmony/data/SouthFoehnData/ALT_1981_1990.dat\", delimiter=\"\\t\", header=1)\n",
    "df_1981_1990[\"date\"] = pd.to_datetime(df_1981_1990[\"Datumsangabe_Zeit\"], format='%Y%m%d %H:%M')\n",
    "df_1981_1990 = df_1981_1990[[\"date\", \"Foehn\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chmony/Apps/anaconda3/envs/develop_xgboost/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_1983_2019 = pd.read_csv(\"/net/litho/atmosdyn2/chmony/data/SouthFoehnData/ALT_1983_2019.dat\", delimiter=\"|\", skiprows=1, header=0, names=range(1,10))\n",
    "df_1983_2019[\"date\"] = pd.to_datetime(df_1983_2019[2], format='%Y%m%d%H%M%S')\n",
    "df_1983_2019[\"Foehn\"] = df_1983_2019[4]\n",
    "df_1983_2019 = df_1983_2019[[\"date\", \"Foehn\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack dataframes. Take the years 1981 and 1982 from df_1981_1990 and the remainder from df_1983_2019\n",
    "df_1981_2019 = pd.concat([df_1981_1990.loc[df_1981_1990[\"date\"] < np.datetime64(\"1983-01-01 00:00:00\")], df_1983_2019], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure continuoes and consistent values in the \"date\" column\n",
    "df_timeframe = pd.Series(pd.date_range(start = \"1981-01-01 00:00:00\", end=\"2019-12-31 23:50:00\", freq=\"10min\"), name=\"date\")\n",
    "df_1981_2019 = pd.merge(df_timeframe, df_1981_2019, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all values in Foehn which are larger than 2 to np.NaN\n",
    "df_1981_2019[\"Foehn\"] = df_1981_2019[\"Foehn\"].mask(df_1981_2019[\"Foehn\"] >2)\n",
    "\n",
    "# Set all Foehn values (Foehn==2) to 1 (i.e. treat Mischluft as normal foehn)\n",
    "df_1981_2019[\"Foehn\"] = df_1981_2019[\"Foehn\"].mask(df_1981_2019[\"Foehn\"] == 2.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rolling window of length 6. If at least 4 dates show Foehn say there is foehn prevalent, otherwise not (refer to Gutermann et. al.(2013))\n",
    "# Allow max 2 missing values (-> min_periods=4). Otherwise set entry to np.NaN\n",
    "foehn_rolling_window=df_1981_2019[\"Foehn\"].rolling(window=6, min_periods=4).sum().shift(-3)\n",
    "foehn_new_representation = (foehn_rolling_window >= 4).astype(int)\n",
    "foehn_new_representation.loc[foehn_rolling_window.isnull()] = np.NaN\n",
    "\n",
    "df_rolling= df_1981_2019.copy()\n",
    "df_rolling[\"Foehn\"]= foehn_new_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only timestamps at full hour and where hour equals 0,6,12 or 18\n",
    "date_mask = (df_rolling[\"date\"].dt.minute==0) & \\\n",
    "            ((df_rolling[\"date\"].dt.hour == 0) | \n",
    "            (df_rolling[\"date\"].dt.hour == 6) |\n",
    "            (df_rolling[\"date\"].dt.hour == 12) |\n",
    "            (df_rolling[\"date\"].dt.hour == 18))\n",
    "df_foehn =df_rolling.loc[date_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foehn.to_csv(\"/net/litho/atmosdyn2/chmony/data/SouthFoehnData/SouthFoehnDataProcessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with meteorological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ERA = pd.read_csv(\"/net/litho/atmosdyn2/chmony/data/MeteorologicalData/ERAI_data.csv.gz\")\n",
    "df_ERA[\"date\"] = pd.to_datetime(df_ERA[\"date\"], format=\"%Y-%m-%dT%H:%M:00.000000Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(left=df_foehn, right = df_ERA, how=\"inner\", on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"/net/litho/atmosdyn2/chmony/data/FoehnAndMeteorologicalData/ERAI_and_Foehn_data.csv.gz\", index=False, compression=\"infer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
